---
title: "Self-driving cars: The unlikely force of eugenics"
date: 2018-03-20
---

Sunday night was marked in history for the first casualty by a self-driving car. 49-year-old Elaine Herzberg unexpectedly emerged from the shadows attempting to cross a roadway and [was struck dead by an Uber driving in autonomous mode](https://www.reuters.com/article/us-autos-selfdriving-uber/self-driving-uber-car-kills-arizona-woman-crossing-street-idUSKBN1GV296).

At the time of writing it appears that [the self-driving car was not at fault](http://fortune.com/2018/03/19/uber-self-driving-car-crash/). Yet there is an interesting bit to this story. Herzberg was a rather untypical pedestrian, so to speak: not only was she walking her bike across the road but also she is believed she have been homeless.

I cannot help but think of a future where *artificial selection* happens as a byproduct of model training biases. People walking their bikes, homeless people, people acting unlike everyone else, people dressed unusually, people putting words together in weird ways â€“ the further from the norm, the harder for machines to deal with you adequately. And so you end up cut out from technologies cause the machine cannot understand what you are telling it, outcast from the social world cause the machine is having trouble building your psychological profile, and killed cause the machine mistook your fancy hat for a knife.