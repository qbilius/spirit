---
title: World model
date: 2020-07-28
---

As long as I have certain goals I want to optimize for in my life, a general **reinforcement learning** paradigm applies: **learn to predict what might happen in the future** and take actions based on these predictions so that we are more sure to achieve whatever goals we have in mind.

We may start this optimization by observing, in a slight modification of the **Stoic philosophy**, that **we have a good amount of control of our own actions and reactions to what is going on around us, and this ability to control things rapidly decreases the further it gets from us**. We may still have some control over our spouses and kids, even less over our colleagues, very little at the level of an entire country, and none over the entire universe or the laws of physics. Thus, our predictive power depends to a large extent on finding strategies (actions) to deal with ourselves: how we react to event happening in the world that are not under our control and what actions we take. Stoics pointed out that endurance, medidation, wisdom and life experience, and fairness are the main virtues to lead a good life.

We can further increase our predictive power by learning to take actions that would lead to predictive behaviors in our **surroundings**. For instance, if you take a good care of your family, this will likely cause pretty stable, rational behaviors; if you vote for competent politicians, there is a slightly higher chance that they will do good for the country; and so on. But the more people are involved in those matters and the further away you are from them, the less control you have, so there is little we can do about it.

At a societal level, I can point out two factors where one may have quite a bit of an influence: education and economic growth. Education makes people more able to take control of their own lives and act more optimally, which presumably converges to similar strategies being applied (e.g., instead of stealing, people might be more likely to earn an honest living). Economic growth, as Peter Thiel advocates, allows **everyone to get slightly more than before and thus have a chance of keeping their needs met.** We can contribute towards that goal by innovating, that is, creating new things of great economic value.

Economic value arises directly from what people need. The more they need something, the more valuable it is. A good summary of what people might want is provided by **[Maslow's Hierarchy of Needs](https://en.wikipedia.org/wiki/Maslow%27s_hierarchy_of_needs)**. Everybody must satisfy their physiological needs, such as water, food, sleep, safety. When these needs are met, more subtle pshychological motivations kick in, such as friendship, love, respect. Finally, people may want to fulfill certain personal goals, such as creativity or curiosity.

Failing to fulfill lower level needs will result in a greater instability in society. Hungry people are more dangerous than failed poets. This is because failing to meet basic needs results in **pain** that, as Jordan Peterson points out, is an undeniable and debilitating sensation. You may have doubts if you're a good poet but pain is something that takes over you completely and your primary objective becomes its minimization at any cost.

To put these points together, my idea is to use AI to innovate in the fields of

- food, water, air, and energy production,
- health and physical safety solutions,
- affordable housing and urban planning,
- personalized, high-throughput education.

Those who can cater for these needs have a threefold advantage:

- They can make sure society is stable.
- They are always in demand, meaning that they can exchange what they produce with whatever else they need.
- They make sure their own basic needs are met.